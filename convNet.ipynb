{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: conv1_1  size: (1, 512, 512, 64)\n",
      "layer: conv1_2  size: (1, 512, 512, 64)\n",
      "layer: conv1_3  size: (1, 512, 512, 128)\n",
      "layer: pool1  size: (1, 256, 256, 64)\n",
      "layer: conv2_1  size: (1, 256, 256, 64)\n",
      "layer: conv2_2  size: (1, 256, 256, 128)\n",
      "layer: conv2_3  size: (1, 256, 256, 128)\n",
      "layer: pool2  size: (1, 128, 128, 128)\n",
      "layer: conv3_1  size: (1, 128, 128, 64)\n",
      "layer: conv3_2  size: (1, 128, 128, 128)\n",
      "layer: conv3_3  size: (1, 128, 128, 128)\n",
      "layer: unpool2  size: (1, 256, 256, 128)\n",
      "layer: conv4_1  size: (1, 256, 256, 64)\n",
      "layer: conv4_2  size: (1, 256, 256, 128)\n",
      "layer: conv4_3  size: (1, 256, 256, 128)\n",
      "layer: unpool1  size: (1, 512, 512, 128)\n",
      "layer: conv5_1  size: (1, 512, 512, 64)\n",
      "layer: conv5_2  size: (1, 512, 512, 128)\n",
      "layer: conv5_3  size: (1, 512, 512, 128)\n",
      "layer: conv5_4  size: (1, 512, 512, 64)\n",
      "layer: score  size: (1, 512, 512, 2)\n",
      "loghts size:  (262144, 2)\n",
      "cross entropy size:  (262144,)\n",
      "prediction size:  (1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from my_tf_layer import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from time import gmtime,strftime\n",
    "\n",
    "\n",
    "seed = 15  # random seed\n",
    "random.seed(seed)\n",
    "\n",
    "nchannel = 1\n",
    "crop_size = 512\n",
    "batch = 1\n",
    "\n",
    "data = tf.placeholder(tf.float32, [batch, crop_size,crop_size,nchannel])\n",
    "label =  tf.placeholder(tf.int32, [1, crop_size,crop_size])\n",
    "expected = tf.expand_dims(label, -1)\n",
    "device = '/gpu:0'\n",
    "\n",
    "out_size = 64\n",
    "conv1_1 = conv2d_layer(data,3,out_size,name = 'conv1_1')\n",
    "conv1_1 = batch_norm_layer(conv1_1,name = 'conv1_1_bn')\n",
    "\n",
    "out_size = 64\n",
    "conv1_2 = conv2d_layer(conv1_1,3,out_size,name = 'conv1_2')\n",
    "conv1_2 = batch_norm_layer(conv1_2,name = 'conv1_2_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv1_3 = conv2d_layer(conv1_2,3,out_size,name = 'conv1_3')\n",
    "conv1_3 = batch_norm_layer(conv1_2,name = 'conv1_3_bn')\n",
    "\n",
    "# pool1\n",
    "pool1 = pool_layer(conv1_3,device=device,name='pool1')\n",
    "\n",
    "out_size = 64\n",
    "conv2_1 = conv2d_layer(pool1,3,out_size,name = 'conv2_1')\n",
    "conv2_1 = batch_norm_layer(conv2_1,name = 'conv2_1_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv2_2 = conv2d_layer(conv2_1,3,out_size,name = 'conv2_2')\n",
    "conv2_2 = batch_norm_layer(conv2_2,name = 'conv2_2_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv2_3 = conv2d_layer(conv2_2,3,out_size,name = 'conv2_3')\n",
    "conv2_3 = batch_norm_layer(conv2_3,name = 'conv2_3_bn')\n",
    "\n",
    "pool2 = pool_layer(conv2_3,device=device,name='pool2')\n",
    "\n",
    "out_size = 64\n",
    "conv3_1 = conv2d_layer(pool2,3,out_size,name = 'conv3_1')\n",
    "conv3_1 = batch_norm_layer(conv3_1,name = 'conv3_1_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv3_2 = conv2d_layer(conv3_1,3,out_size,name = 'conv3_2')\n",
    "conv3_2 = batch_norm_layer(conv3_2,name = 'conv3_2_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv3_3 = conv2d_layer(conv3_2,3,out_size,name = 'conv3_3')\n",
    "conv3_3 = batch_norm_layer(conv3_3,name = 'conv3_3_bn')\n",
    "\n",
    "# un pooling layer\n",
    "un_pool2 = up_pool_deconv_layer(conv3_3,2,name = 'unpool2')\n",
    "\n",
    "out_size = 64\n",
    "conv4_1 = conv2d_layer(un_pool2,3,out_size,name = 'conv4_1')\n",
    "conv4_1 = batch_norm_layer(conv4_1,name = 'conv4_1_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv4_2 = conv2d_layer(conv4_1,3,out_size,name = 'conv4_2')\n",
    "conv4_2 = batch_norm_layer(conv4_2,name = 'conv4_2_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv4_3 = conv2d_layer(conv4_2,3,out_size,name = 'conv4_3')\n",
    "conv4_3 = batch_norm_layer(conv4_3,name = 'conv4_3_bn')\n",
    "\n",
    "un_pool1 = up_pool_deconv_layer(conv4_3,2,name='unpool1')\n",
    "\n",
    "out_size = 64\n",
    "conv5_1 = conv2d_layer(un_pool1,3,out_size,name = 'conv5_1')\n",
    "conv5_1 = batch_norm_layer(conv5_1,name = 'conv5_1_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv5_2 = conv2d_layer(conv5_1,3,out_size,name = 'conv5_2')\n",
    "conv5_2 = batch_norm_layer(conv5_2,name = 'conv5_2_bn')\n",
    "\n",
    "out_size = 128\n",
    "conv5_3 = conv2d_layer(conv5_2,3,out_size,name = 'conv5_3')\n",
    "conv5_3 = batch_norm_layer(conv5_3,name = 'conv5_3_bn')\n",
    "\n",
    "out_size = 64\n",
    "conv5_4 = conv2d_layer(conv5_3,3,out_size,name = 'conv5_4')\n",
    "conv5_4 = batch_norm_layer(conv5_4,name = 'conv5_4_bn')\n",
    "\n",
    "classes = 2\n",
    "score = conv2d_layer(conv5_4,1,classes,name='score')\n",
    "\n",
    "logits = tf.reshape(score,(-1,2))\n",
    "print 'loghts size: ',logits.get_shape()\n",
    "\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, tf.reshape(expected, [-1]), name='x_entropy')\n",
    "print 'cross entropy size: ',cross_entropy.get_shape()\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "rate = 0.0001\n",
    "optimize = tf.train.AdamOptimizer(rate,0.5).minimize(loss)\n",
    "#optimize = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(loss)\n",
    "th = 0.5\n",
    "prediction = tf.argmax(tf.reshape(tf.nn.softmax(logits), tf.shape(score)), dimension=3)\n",
    "print 'prediction size: ',prediction.get_shape()\n",
    "#prediction = tf.floor(tf.reshape(tf.nn.softmax(logits), tf.shape(score))+0.5)\n",
    "#print 'prediction size: ',prediction.get_shape()\n",
    "accuracy = tf.div(tf.cast(tf.reduce_sum(prediction+tf.cast(label,tf.int64)),tf.float32),tf.cast(crop_size*crop_size,tf.float32))\n",
    "#accuracy = tf.div(tf.cast(tf.reduce_sum(tf.pow(tf.round(prediction - tf.cast(label,tf.int64)),2)),tf.float32),crop_size*crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/D/SpineDataset/spine_seg/image/AKa21.jpg', '/media/D/SpineDataset/spine_seg/label/AKA2_mask1.png']\n",
      "step0 -- accuracy is 0.426837921143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_list = '/home/qinshuo/WorkPlace/caffe_space/seg_spine/spine_list/train_list.txt'\n",
    "path = '/media/D/SpineDataset/spine_seg'\n",
    "train_data = []\n",
    "with open(train_list,'r') as ff:\n",
    "    for line in ff:\n",
    "        train_data.append([path+vv for vv in line.split()])\n",
    "print train_data[0]\n",
    "\n",
    "#show_image(read_img(train_data[0][0]),read_img(train_data[0][1]))\n",
    "\n",
    "# enable multiple device\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "iter = 0\n",
    "idx = random.randint(0, len(train_data)-1)\n",
    "batch_xs = read_image(train_data[idx][0],size=crop_size)\n",
    "batch_ys = read_label(train_data[idx][1],size=crop_size)\n",
    "sess.run(optimize,feed_dict = {data: batch_xs,label: batch_ys})\n",
    "print 'step{} -- accuracy is {}'.format(iter,sess.run(accuracy,feed_dict = {data: batch_xs,label: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat, 14 Jan 2017 14:02:01-step4 -- accuracy is 0.45779800415\n",
      "Model saved in file: checkpoint/14-02-02.ckpt\n",
      "Sat, 14 Jan 2017 14:02:17-step9 -- accuracy is 0.42599105835\n",
      "Model saved in file: checkpoint/14-02-18.ckpt"
     ]
    }
   ],
   "source": [
    "for iter in range(50000):\n",
    "    idx = random.randint(0, len(train_data)-1)\n",
    "    rotate = random.randint(0,360)\n",
    "    batch_xs = read_image(train_data[idx][0],rotate = rotate,size=crop_size)\n",
    "    batch_ys = read_label(train_data[idx][1],rotate = rotate,size=crop_size)\n",
    "    sess.run(optimize,feed_dict = {data: batch_xs,label: batch_ys})\n",
    "    if (iter+1)%200 == 0:\n",
    "        print '{}-step{} -- accuracy is {}'.format(strftime(\"%a, %d %b %Y %H:%M:%S\", gmtime()),iter,sess.run(accuracy,feed_dict = {data: batch_xs,label: batch_ys}))\n",
    "    if (iter+1)%10000 == 0:\n",
    "        save_path = strftime(\"checkpoint/%H-%M-%S.ckpt\",gmtime())\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess,save_path)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        ss = score.eval(session = sess,feed_dict = {data: batch_xs,label: batch_ys})\n",
    "        ss2 = ss.reshape(-1,crop_size,crop_size)\n",
    "        show_image(ss2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-383ac3d4d454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_xs' is not defined"
     ]
    }
   ],
   "source": [
    "ss = score.eval(session = sess,feed_dict = {data: batch_xs,label: batch_ys})\n",
    "ss2 = ss.reshape(-1,512,512)\n",
    "truth = batch_ys.reshape(512,512)\n",
    "show_image(ss2[0],truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
